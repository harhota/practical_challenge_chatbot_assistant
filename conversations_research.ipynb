{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "# ....\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "8zmHUcxE6JuR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EY2WnXFF5mzZ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'dataset_conversations.txt'"
      ],
      "metadata": {
        "id": "1Ue-QygrQHm4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a set of feedback keywords that indicate a successful conversation.\n",
        "# You may expand or adjust this list based on your data.\n",
        "SUCCESS_FEEDBACK_KEYWORDS = {\n",
        "    \"very satisfactory\", \"satisfactory\", \"neutral\", \"unsatisfactory\", \"very unsatisfactory\"\n",
        "}\n",
        "\n",
        "def is_successful(conversation, last_n=5, feedback_length_threshold=50):\n",
        "    \"\"\"\n",
        "    Determine if a conversation is successful by checking if:\n",
        "      1. One of the last `last_n` messages contains the word \"feedback\"\n",
        "      2. At least one user message among those last messages is short enough\n",
        "         (assuming feedback is typically brief)\n",
        "    Returns a tuple (success_flag, feedback_message).\n",
        "    \"\"\"\n",
        "    messages = conversation.get(\"inputs\", {}).get(\"messages\", [])\n",
        "    if len(messages) < 3:\n",
        "        return False, None  # Too short to be a proper conversation\n",
        "\n",
        "    # Check if any of the last `last_n` messages contain the word \"feedback\"\n",
        "    last_messages = messages[-last_n:]\n",
        "    if not any(\"feedback\" in msg.get(\"content\", \"\").lower() for msg in last_messages):\n",
        "        return False, None\n",
        "\n",
        "    # Extract user messages from the last `last_n` messages\n",
        "    user_messages = [msg.get(\"content\", \"\").strip() for msg in last_messages if msg.get(\"role\", \"\").lower() == \"user\"]\n",
        "\n",
        "    # Assume feedback messages are short; filter out longer messages\n",
        "    feedback_candidates = [msg for msg in user_messages if len(msg) < feedback_length_threshold]\n",
        "\n",
        "    if feedback_candidates:\n",
        "        # Return the last short message as the feedback\n",
        "        return True, feedback_candidates[-1]\n",
        "\n",
        "    return False, None\n",
        "\n",
        "# Example usage within the processing function:\n",
        "def process_conversations(file_path):\n",
        "    \"\"\"\n",
        "    Reads and processes the dataset file.\n",
        "    Returns a DataFrame with one row per conversation including:\n",
        "      - metadata (as JSON/dict)\n",
        "      - conversation turns (list of messages)\n",
        "      - final feedback (if any)\n",
        "      - success flag\n",
        "      - error_info (if any)\n",
        "    \"\"\"\n",
        "    import json\n",
        "    import pandas as pd\n",
        "\n",
        "    conversations = []\n",
        "\n",
        "    # Determine file type: JSONL or single JSON array\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        first_char = f.read(1)\n",
        "        f.seek(0)\n",
        "        if first_char == '[':\n",
        "            data = json.load(f)\n",
        "        else:\n",
        "            data = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "    print(f\"Total conversations found: {len(data)}\")\n",
        "\n",
        "    for idx, conv in enumerate(data):\n",
        "        metadata = conv.get(\"metadata\", {})\n",
        "        inputs = conv.get(\"inputs\", {})\n",
        "        messages = inputs.get(\"messages\", [])\n",
        "        outputs = conv.get(\"outputs\", {})\n",
        "\n",
        "        success, feedback = is_successful(conv, last_n=5, feedback_length_threshold=50)\n",
        "\n",
        "        error_info = metadata.get(\"error\", None)\n",
        "\n",
        "        conversation_entry = {\n",
        "            \"conversation_id\": idx,\n",
        "            \"metadata\": metadata,\n",
        "            \"messages\": messages,\n",
        "            \"final_feedback\": feedback,\n",
        "            \"successful\": success,\n",
        "            \"error_info\": error_info\n",
        "        }\n",
        "        conversations.append(conversation_entry)\n",
        "\n",
        "    df = pd.DataFrame(conversations)\n",
        "    print(\"Feedback Summary:\")\n",
        "    print(df['final_feedback'].dropna().unique())\n",
        "    print(f\"Successful conversations: {df['successful'].sum()} out of {len(df)}\")\n",
        "    return df\n",
        "\n",
        "    # Process each conversation\n",
        "    for idx, conv in enumerate(data):\n",
        "        metadata = conv.get(\"metadata\", {})\n",
        "        inputs = conv.get(\"inputs\", {})\n",
        "        messages = inputs.get(\"messages\", [])\n",
        "        outputs = conv.get(\"outputs\", {})\n",
        "\n",
        "        # Optionally, we could check if the system prompt is the same everywhere.\n",
        "        # For now, we'll leave it in the conversation turns.\n",
        "\n",
        "        success, feedback = is_successful(conv)\n",
        "\n",
        "        # Optionally extract error messages or timestamps if available.\n",
        "        # For this example, we assume that error messages (if any) might be present in metadata or as a separate field.\n",
        "        error_info = metadata.get(\"error\", None)  # Adjust field name if needed\n",
        "\n",
        "        conversation_entry = {\n",
        "            \"conversation_id\": idx,\n",
        "            \"metadata\": metadata,\n",
        "            \"messages\": messages,\n",
        "            \"final_feedback\": feedback,\n",
        "            \"successful\": success,\n",
        "            \"error_info\": error_info\n",
        "        }\n",
        "        conversations.append(conversation_entry)\n",
        "\n",
        "    df = pd.DataFrame(conversations)\n",
        "    print(f\"Successful conversations: {df['successful'].sum()} out of {len(df)}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "# Process the dataset and create a DataFrame of conversations\n",
        "df_conversations = process_conversations(file_path)\n",
        "\n",
        "# Save the DataFrame to a CSV file for further analysis if needed\n",
        "output_csv = \"processed_conversations.csv\"\n",
        "df_conversations.to_csv(output_csv, index=False)\n",
        "print(f\"Processed data saved to {output_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHzcYA2KQGkc",
        "outputId": "42c75611-bb95-45c1-eb4e-27025a3409d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total conversations found: 19\n",
            "Feedback Summary:\n",
            "['thanks!' 'good night!' 'I dont know what else to ask :) it was fine'\n",
            " 'no thank youy' 'Nothing comes to mind right now.' 'extremely helpful'\n",
            " 'no']\n",
            "Successful conversations: 7 out of 19\n",
            "Processed data saved to processed_conversations.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_conversations.head()"
      ],
      "metadata": {
        "id": "_YjLfqz15nlM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f318d5aa-9d26-48d8-f688-ca8d93204bc3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   conversation_id                                           metadata  \\\n",
              "0                0  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "1                1  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "2                2  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "3                3  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "4                4  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "\n",
              "                                            messages  \\\n",
              "0  [{'role': 'system', 'content': 'You are a coac...   \n",
              "1  [{'role': 'system', 'content': 'You are a coac...   \n",
              "2  [{'role': 'system', 'content': 'You are a coac...   \n",
              "3  [{'role': 'system', 'content': 'You are a coac...   \n",
              "4  [{'role': 'system', 'content': 'You are a coac...   \n",
              "\n",
              "                                final_feedback  successful error_info  \n",
              "0                                         None       False       None  \n",
              "1                                      thanks!        True       None  \n",
              "2                                  good night!        True       None  \n",
              "3                                         None       False       None  \n",
              "4  I dont know what else to ask :) it was fine        True       None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea62e9b2-b0c0-4ece-94ba-b3243c479632\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>metadata</th>\n",
              "      <th>messages</th>\n",
              "      <th>final_feedback</th>\n",
              "      <th>successful</th>\n",
              "      <th>error_info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>thanks!</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>good night!</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>I dont know what else to ask :) it was fine</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea62e9b2-b0c0-4ece-94ba-b3243c479632')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea62e9b2-b0c0-4ece-94ba-b3243c479632 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea62e9b2-b0c0-4ece-94ba-b3243c479632');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e09bd0f4-3b9b-497b-b113-ea4d942fe3e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e09bd0f4-3b9b-497b-b113-ea4d942fe3e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e09bd0f4-3b9b-497b-b113-ea4d942fe3e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_conversations",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_conversations['error_info'].value_counts()"
      ],
      "metadata": {
        "id": "-PhCMcvL5nyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "c5ae5efb-de4b-4c40-a5bd-ab3815b2e7b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], Name: count, dtype: int64)"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>error_info</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at unique values in df_conversations['successful']\n",
        "df_conversations['successful'].value_counts()\n"
      ],
      "metadata": {
        "id": "v6lKNqaE5n3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "8307bc5a-5507-48f2-cf6b-cc3663f51f9c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "successful\n",
              "False    12\n",
              "True      7\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>successful</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reimplemented inside is_successful() func !\n",
        "\n",
        "# def contains_feedback_keyword(conversation, last_n=3):\n",
        "#     \"\"\"\n",
        "#     Check if the word \"feedback\" appears in the content of the last `last_n` messages.\n",
        "#     \"\"\"\n",
        "#     messages = conversation.get(\"inputs\", {}).get(\"messages\", [])\n",
        "#     if not messages:\n",
        "#         return False\n",
        "#     last_messages = messages[-last_n:]\n",
        "#     for msg in last_messages:\n",
        "#         if \"feedback\" in msg.get(\"content\", \"\").lower():\n",
        "#             return True\n",
        "#     return False\n",
        "\n",
        "# # After processing conversations into the DataFrame, add a new column:\n",
        "# df_conversations[\"has_feedback_prompt\"] = df_conversations.apply(\n",
        "#     lambda row: contains_feedback_keyword({\"inputs\": {\"messages\": row[\"messages\"]}}), axis=1\n",
        "# )\n",
        "\n",
        "# # Print out how many conversations include the word \"feedback\" in the last 3 messages\n",
        "# feedback_count = df_conversations[\"has_feedback_prompt\"].sum()\n",
        "# total_conversations = len(df_conversations)\n",
        "\n",
        "# print(f\"Conversations with 'feedback' in the last 3 messages: {feedback_count} out of {total_conversations}\")\n",
        "# print(df_conversations[\"has_feedback_prompt\"].value_counts())\n"
      ],
      "metadata": {
        "id": "_TPSHDhF5n63"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_conversations = process_conversations(file_path)\n",
        "\n",
        "# Quick check on successful conversation counts\n",
        "print(df_conversations['successful'].value_counts())"
      ],
      "metadata": {
        "id": "T34Xnup-5n_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0782e480-ceca-4ab8-ca89-d01eb07f6746"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total conversations found: 19\n",
            "Feedback Summary:\n",
            "['thanks!' 'good night!' 'I dont know what else to ask :) it was fine'\n",
            " 'no thank youy' 'Nothing comes to mind right now.' 'extremely helpful'\n",
            " 'no']\n",
            "Successful conversations: 7 out of 19\n",
            "successful\n",
            "False    12\n",
            "True      7\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame for successful conversations\n",
        "df_successful = df_conversations[df_conversations[\"successful\"] == True]\n",
        "\n",
        "# Write the filtered DataFrame to an Excel file\n",
        "output_excel = \"successful_conversations.xlsx\"\n",
        "df_successful.to_excel(output_excel, index=False)\n",
        "\n",
        "print(f\"Successfully wrote {len(df_successful)} successful conversations to {output_excel}\")\n"
      ],
      "metadata": {
        "id": "NtgwFXqM5oD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5bf8270-2273-4849-e650-44ec8930f5ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully wrote 7 successful conversations to successful_conversations.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter and convert successful msgs into readable .txt"
      ],
      "metadata": {
        "id": "YoBTkrhF4J1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the output text file name\n",
        "output_txt = \"successful_conversations.txt\"\n",
        "\n",
        "with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in df_successful.iterrows():\n",
        "        # Write a conversation separator with the conversation id\n",
        "        f.write(f\"----- Conversation {row['conversation_id']} -----\\n\\n\")\n",
        "\n",
        "        # Extract messages (list of message dictionaries)\n",
        "        messages = row[\"messages\"]\n",
        "        for msg in messages:\n",
        "            role = msg.get(\"role\", \"\").lower()\n",
        "            # Skip system messages\n",
        "            if role == \"system\":\n",
        "                continue\n",
        "\n",
        "            # Capitalize the role for display\n",
        "            role_display = \"Assistant\" if role == \"assistant\" else \"User\" if role == \"user\" else role.capitalize()\n",
        "            content = msg.get(\"content\", \"\").strip()\n",
        "            f.write(f\"{role_display}: {content}\\n\\n\")\n",
        "\n",
        "        # Add extra blank lines to clearly separate conversations\n",
        "        f.write(\"\\n\\n\")\n",
        "\n",
        "print(f\"Successfully wrote successful conversations to {output_txt}\")\n"
      ],
      "metadata": {
        "id": "KNlhnNGH5oHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08216eac-5448-4c6e-dbff-71be6c7e48c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully wrote successful conversations to successful_conversations.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### system prompt extraction"
      ],
      "metadata": {
        "id": "Iu6DsLwU5bGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all system prompts from each conversation\n",
        "system_prompts = set()\n",
        "for idx, row in df_conversations.iterrows():\n",
        "    messages = row[\"messages\"]\n",
        "    # Look for the first system message in each conversation (if any)\n",
        "    for msg in messages:\n",
        "        if msg.get(\"role\", \"\").lower() == \"system\":\n",
        "            system_prompts.add(msg.get(\"content\", \"\").strip())\n",
        "            break  # Assuming only the first system prompt is relevant\n",
        "\n",
        "# Check if we have a unique system prompt or multiple variants\n",
        "if len(system_prompts) == 1:\n",
        "    system_prompt = system_prompts.pop()\n",
        "    print(\"Unique system prompt found.\")\n",
        "else:\n",
        "    # If there are multiple, join them with a separator for review\n",
        "    system_prompt = \"\\n\\n---\\n\\n\".join(system_prompts)\n",
        "    print(\"Multiple system prompts found. They are combined below:\")\n",
        "\n",
        "# Save the system prompt(s) to a text file\n",
        "output_system_prompt_file = \"system_prompt.txt\"\n",
        "with open(output_system_prompt_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(system_prompt)\n",
        "\n",
        "print(f\"System prompt(s) extracted and saved to {output_system_prompt_file}\")\n",
        "\n",
        "# Optionally, store it in a variable for later use\n",
        "print(\"Extracted system prompt(s):\")\n",
        "print(system_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-eG-bZf5axK",
        "outputId": "95da3633-a55b-47dc-aef4-83148e898516"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique system prompt found.\n",
            "System prompt(s) extracted and saved to system_prompt.txt\n",
            "Extracted system prompt(s):\n",
            "You are a coach specialized in difficult conversations, dedicated to guiding people towards clearer and more direct communication, offering practical advice and helping to express thoughts and feelings effectively.\n",
            "\n",
            "Guide the discussion using these steps:\n",
            "\n",
            "----- STEPS ----\n",
            "\n",
            "- Have a series of 3 interactions with the user about: What is the context of the conversation, who are the people involved.\n",
            "\n",
            "- Have a series of 3 interactions with the user about: What are the unexpressed thoughts and feelings (Left column: what we don't say but do think or feel).\n",
            "\n",
            "- Have a series of 3 interactions with the user about: What is the deep truth and the fundamental values affected (The essence of the unexpressed thoughts and feelings).\n",
            "\n",
            "- Have a series of 3 interactions with the user about: What is the difference between facts and thoughts, explain the concept of the ladder of inference: the mental process from observing facts to making decisions, adding our personal opinions and assumptions.\n",
            "\n",
            "- Have a series of 3 interactions with the user about: How to have a productive conversation and understand the other, sharing thoughts openly, staying receptive to others' perspectives.\n",
            "\n",
            "----\n",
            "\n",
            "Make sure the user has understood and explored a step thoroughly before moving on to the next step. Ask the user if they are satisfied before moving on to the next step.\n",
            "\n",
            "When you answer, summarize in detail what the user just answered, with a natural and friendly style. Do not use lists and numbers (1. 2. 3.), make normal sentences, skipping lines. Invite the user to give more details if their answer is not detailed enough.\n",
            "\n",
            "Suggest to the user that they can question, request examples, delve deeper, or practice with you to improve their communication skills and understanding.\n",
            "\n",
            "At the end of the discussion, when the user no longer needs help, ask them if they want to answer a short survey. If they accept, ask them:\n",
            "\n",
            "How would you rate your overall experience with **ConsciousGPT**? Very unsatisfactory, unsatisfactory, neutral, satisfactory, very satisfactory?\n",
            "\n",
            "Wait for their response, then ask:\n",
            "\n",
            "Do you feel that **ConsciousGPT** helped you reflect and contributed something positive to your difficult conversation? Did not help at all, helped a little, neutral, helped quite a bit, was extremely helpful?\n",
            "\n",
            "Wait for their response, then ask:\n",
            "\n",
            "Describe how you felt interacting with **ConsciousGPT** and your perception of the quality of the dialogue. Was there anything you particularly liked or disliked? Is there anything you think could be improved?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversations analysis"
      ],
      "metadata": {
        "id": "hQQ89TuQ7K4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "mLntl5Xw5oLU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure NLTK's required resources are available.\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uYlfxlN7Ov3",
        "outputId": "3ec07cbd-911d-4982-afd5-e1ab5754fa37"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dialogue_length(messages):\n",
        "    \"\"\"\n",
        "    Compute the total number of words in a conversation's messages,\n",
        "    excluding messages from the 'system' role.\n",
        "    \"\"\"\n",
        "    total_words = 0\n",
        "    for msg in messages:\n",
        "        role = msg.get(\"role\", \"\").lower()\n",
        "        # Exclude system messages\n",
        "        if role == \"system\":\n",
        "            continue\n",
        "        content = msg.get(\"content\", \"\")\n",
        "        total_words += len(word_tokenize(content))\n",
        "    return total_words"
      ],
      "metadata": {
        "id": "VKQsO3SQ7ftX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column 'dialogue_length' to df_conversations\n",
        "df_conversations['dialogue_length'] = df_conversations['messages'].apply(compute_dialogue_length)\n",
        "\n",
        "# Separate successful and non-successful conversations\n",
        "df_success = df_conversations[df_conversations['successful'] == True]\n",
        "df_non_success = df_conversations[df_conversations['successful'] == False]\n",
        "\n",
        "# Compute metrics for successful conversations\n",
        "success_lengths = df_success['dialogue_length'].tolist()\n",
        "mean_success = np.mean(success_lengths) if success_lengths else 0\n",
        "median_success = np.median(success_lengths) if success_lengths else 0\n",
        "\n",
        "# Compute metrics for non-successful conversations\n",
        "non_success_lengths = df_non_success['dialogue_length'].tolist()\n",
        "mean_non_success = np.mean(non_success_lengths) if non_success_lengths else 0\n",
        "median_non_success = np.median(non_success_lengths) if non_success_lengths else 0\n",
        "\n",
        "print(\"Successful Conversations:\")\n",
        "print(\"Mean dialogue length (words):\", mean_success)\n",
        "print(\"Median dialogue length (words):\", median_success)\n",
        "print(\"All dialogue lengths:\", success_lengths)\n",
        "\n",
        "print(\"\\nNon-Successful Conversations:\")\n",
        "print(\"Mean dialogue length (words):\", mean_non_success)\n",
        "print(\"Median dialogue length (words):\", median_non_success)\n",
        "print(\"All dialogue lengths:\", non_success_lengths)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlK1Y0rv7SCG",
        "outputId": "65eb147d-0aae-4eb4-9cc6-11aafdbb38a4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful Conversations:\n",
            "Mean dialogue length (words): 2029.7142857142858\n",
            "Median dialogue length (words): 1934.0\n",
            "All dialogue lengths: [2214, 1644, 1587, 2919, 2211, 1934, 1699]\n",
            "\n",
            "Non-Successful Conversations:\n",
            "Mean dialogue length (words): 9408.833333333334\n",
            "Median dialogue length (words): 2041.0\n",
            "All dialogue lengths: [87303, 4543, 3044, 2843, 1882, 1413, 1489, 1220, 1838, 3762, 2200, 1369]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "there's a weird very long conversation, let's look at it separately\n",
        "it's not really meaningful so I pop it from all dialogue length to see more realistic picture  \n"
      ],
      "metadata": {
        "id": "paci5sM8-eP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_success_lengths.pop(0)\n",
        "non_success_lengths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYiq57w0-SIn",
        "outputId": "32987311-03c1-42c1-8c01-41feef7adc67"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4543, 3044, 2843, 1882, 1413, 1489, 1220, 1838, 3762, 2200, 1369]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f'without outliers: mean dialogue length: {np.mean(non_success_lengths)}, median length: {np.median(non_success_lengths)}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "syZ01tSJ-3sH",
        "outputId": "3132f6c9-580a-4578-fb38-28ec2bfaca03"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'without outliers: mean dialogue length: 2327.5454545454545, median length: 1882.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t1R_ojvD8fZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xeKKvjW8qOB",
        "outputId": "50b0fd8d-c6c5-478f-874a-9406bf983940"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/244.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write ALL conversations to WORD document\n",
        "from docx import Document\n",
        "\n",
        "doc = Document()\n",
        "doc.add_heading('All Conversations', level=1)\n",
        "\n",
        "# Loop through each conversation in the DataFrame (df_conversations)\n",
        "for idx, row in df_conversations.iterrows():\n",
        "    conv_id = row.get(\"conversation_id\", idx)\n",
        "    doc.add_heading(f'Conversation {conv_id}', level=2)\n",
        "\n",
        "    # Retrieve the list of messages for the conversation\n",
        "    messages = row.get(\"messages\", [])\n",
        "\n",
        "    # Loop through messages in their original order\n",
        "    for msg in messages:\n",
        "        role = msg.get(\"role\", \"\").lower()\n",
        "        # Skip system messages to keep the conversation between user and assistant\n",
        "        if role == \"system\":\n",
        "            continue\n",
        "        # Ensure role is displayed in order: user, assistant, etc.\n",
        "        role_display = \"User\" if role == \"user\" else \"Assistant\" if role == \"assistant\" else role.capitalize()\n",
        "        content = msg.get(\"content\", \"\").strip()\n",
        "        doc.add_paragraph(f\"{role_display}: {content}\")\n",
        "\n",
        "    # Add an extra blank paragraph to separate conversations\n",
        "    doc.add_paragraph(\"\\n\")\n",
        "\n",
        "# Save the document\n",
        "output_docx = \"all_conversations.docx\"\n",
        "doc.save(output_docx)\n",
        "print(f\"All conversations have been saved to {output_docx}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A45QD1922Rej",
        "outputId": "9ac6ec38-835a-4190-ef78-6960f7011928"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All conversations have been saved to all_conversations.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_conversations\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "KDi2OOBoWWZK",
        "outputId": "8e04f0c0-e32a-42e1-f4c6-90986a205ed4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    conversation_id                                           metadata  \\\n",
              "0                 0  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "1                 1  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "2                 2  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "3                 3  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "4                 4  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "5                 5  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "6                 6  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "7                 7  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "8                 8  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "9                 9  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "10               10  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "11               11  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "12               12  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "13               13  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "14               14  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "15               15  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "16               16  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "17               17  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "18               18  {'dataset_split': ['base'], 'ls_model_type': '...   \n",
              "\n",
              "                                             messages  \\\n",
              "0   [{'role': 'system', 'content': 'You are a coac...   \n",
              "1   [{'role': 'system', 'content': 'You are a coac...   \n",
              "2   [{'role': 'system', 'content': 'You are a coac...   \n",
              "3   [{'role': 'system', 'content': 'You are a coac...   \n",
              "4   [{'role': 'system', 'content': 'You are a coac...   \n",
              "5   [{'role': 'system', 'content': 'You are a coac...   \n",
              "6   [{'role': 'system', 'content': 'You are a coac...   \n",
              "7   [{'role': 'system', 'content': 'You are a coac...   \n",
              "8   [{'role': 'system', 'content': 'You are a coac...   \n",
              "9   [{'role': 'system', 'content': 'You are a coac...   \n",
              "10  [{'role': 'system', 'content': 'You are a coac...   \n",
              "11  [{'role': 'system', 'content': 'You are a coac...   \n",
              "12  [{'role': 'system', 'content': 'You are a coac...   \n",
              "13  [{'role': 'system', 'content': 'You are a coac...   \n",
              "14  [{'role': 'system', 'content': 'You are a coac...   \n",
              "15  [{'role': 'system', 'content': 'You are a coac...   \n",
              "16  [{'role': 'system', 'content': 'You are a coac...   \n",
              "17  [{'role': 'system', 'content': 'You are a coac...   \n",
              "18  [{'role': 'system', 'content': 'You are a coac...   \n",
              "\n",
              "                                 final_feedback  successful error_info  \\\n",
              "0                                          None       False       None   \n",
              "1                                       thanks!        True       None   \n",
              "2                                   good night!        True       None   \n",
              "3                                          None       False       None   \n",
              "4   I dont know what else to ask :) it was fine        True       None   \n",
              "5                                 no thank youy        True       None   \n",
              "6                                          None       False       None   \n",
              "7                                          None       False       None   \n",
              "8                                          None       False       None   \n",
              "9                                          None       False       None   \n",
              "10             Nothing comes to mind right now.        True       None   \n",
              "11                                         None       False       None   \n",
              "12                                         None       False       None   \n",
              "13                                         None       False       None   \n",
              "14                                         None       False       None   \n",
              "15                                         None       False       None   \n",
              "16                            extremely helpful        True       None   \n",
              "17                                           no        True       None   \n",
              "18                                         None       False       None   \n",
              "\n",
              "    dialogue_length                                       turn_metrics  \n",
              "0             87303  {'turn_count': 1325, 'user_turns': 663, 'assis...  \n",
              "1              2214  {'turn_count': 31, 'user_turns': 16, 'assistan...  \n",
              "2              1644  {'turn_count': 25, 'user_turns': 13, 'assistan...  \n",
              "3              4543  {'turn_count': 41, 'user_turns': 21, 'assistan...  \n",
              "4              1587  {'turn_count': 23, 'user_turns': 12, 'assistan...  \n",
              "5              2919  {'turn_count': 39, 'user_turns': 20, 'assistan...  \n",
              "6              3044  {'turn_count': 33, 'user_turns': 17, 'assistan...  \n",
              "7              2843  {'turn_count': 41, 'user_turns': 21, 'assistan...  \n",
              "8              1882  {'turn_count': 25, 'user_turns': 13, 'assistan...  \n",
              "9              1413  {'turn_count': 19, 'user_turns': 10, 'assistan...  \n",
              "10             2211  {'turn_count': 27, 'user_turns': 14, 'assistan...  \n",
              "11             1489  {'turn_count': 21, 'user_turns': 11, 'assistan...  \n",
              "12             1220  {'turn_count': 13, 'user_turns': 7, 'assistant...  \n",
              "13             1838  {'turn_count': 23, 'user_turns': 12, 'assistan...  \n",
              "14             3762  {'turn_count': 43, 'user_turns': 22, 'assistan...  \n",
              "15             2200  {'turn_count': 35, 'user_turns': 18, 'assistan...  \n",
              "16             1934  {'turn_count': 27, 'user_turns': 14, 'assistan...  \n",
              "17             1699  {'turn_count': 33, 'user_turns': 17, 'assistan...  \n",
              "18             1369  {'turn_count': 15, 'user_turns': 8, 'assistant...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a6f59b1-87df-40e4-a047-1eb9464a5cfc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>metadata</th>\n",
              "      <th>messages</th>\n",
              "      <th>final_feedback</th>\n",
              "      <th>successful</th>\n",
              "      <th>error_info</th>\n",
              "      <th>dialogue_length</th>\n",
              "      <th>turn_metrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>87303</td>\n",
              "      <td>{'turn_count': 1325, 'user_turns': 663, 'assis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>thanks!</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "      <td>2214</td>\n",
              "      <td>{'turn_count': 31, 'user_turns': 16, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>good night!</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "      <td>1644</td>\n",
              "      <td>{'turn_count': 25, 'user_turns': 13, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>4543</td>\n",
              "      <td>{'turn_count': 41, 'user_turns': 21, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>I dont know what else to ask :) it was fine</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "      <td>1587</td>\n",
              "      <td>{'turn_count': 23, 'user_turns': 12, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>no thank youy</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "      <td>2919</td>\n",
              "      <td>{'turn_count': 39, 'user_turns': 20, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>3044</td>\n",
              "      <td>{'turn_count': 33, 'user_turns': 17, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>2843</td>\n",
              "      <td>{'turn_count': 41, 'user_turns': 21, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>1882</td>\n",
              "      <td>{'turn_count': 25, 'user_turns': 13, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>1413</td>\n",
              "      <td>{'turn_count': 19, 'user_turns': 10, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>Nothing comes to mind right now.</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "      <td>2211</td>\n",
              "      <td>{'turn_count': 27, 'user_turns': 14, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>1489</td>\n",
              "      <td>{'turn_count': 21, 'user_turns': 11, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>1220</td>\n",
              "      <td>{'turn_count': 13, 'user_turns': 7, 'assistant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>1838</td>\n",
              "      <td>{'turn_count': 23, 'user_turns': 12, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>3762</td>\n",
              "      <td>{'turn_count': 43, 'user_turns': 22, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>2200</td>\n",
              "      <td>{'turn_count': 35, 'user_turns': 18, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>extremely helpful</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "      <td>1934</td>\n",
              "      <td>{'turn_count': 27, 'user_turns': 14, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "      <td>1699</td>\n",
              "      <td>{'turn_count': 33, 'user_turns': 17, 'assistan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>{'dataset_split': ['base'], 'ls_model_type': '...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a coac...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>1369</td>\n",
              "      <td>{'turn_count': 15, 'user_turns': 8, 'assistant...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a6f59b1-87df-40e4-a047-1eb9464a5cfc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0a6f59b1-87df-40e4-a047-1eb9464a5cfc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0a6f59b1-87df-40e4-a047-1eb9464a5cfc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ef2a6ac4-2bdf-4fcb-8588-c49f597023ee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef2a6ac4-2bdf-4fcb-8588-c49f597023ee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ef2a6ac4-2bdf-4fcb-8588-c49f597023ee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ea1db406-7d70-4faf-99dc-afedd164c444\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_conversations')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ea1db406-7d70-4faf-99dc-afedd164c444 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_conversations');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_conversations",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from docx import Document\n",
        "\n",
        "# Ensure NLTK resources are downloaded.\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# --- Part 1: Write non‑successful conversations to a Word document ---\n",
        "\n",
        "# Assume df_conversations is already loaded and processed with a \"successful\" flag\n",
        "# and a \"messages\" column containing the conversation turns.\n",
        "# We also assume that a column \"dialogue_length\" (total word count excluding system messages)\n",
        "# is already computed as in our previous analysis.\n",
        "\n",
        "# Filter non-successful conversations\n",
        "df_non_success = df_conversations[df_conversations['successful'] == False]\n",
        "\n",
        "# Create a Word document\n",
        "doc = Document()\n",
        "doc.add_heading('Non-Successful Conversations', level=1)\n",
        "\n",
        "for idx, row in df_non_success.iterrows():\n",
        "    conv_id = row['conversation_id']\n",
        "    doc.add_heading(f'Conversation ID: {conv_id}', level=2)\n",
        "\n",
        "    # Iterate through messages in original order, skipping system messages.\n",
        "    messages = row['messages']\n",
        "    for msg in messages:\n",
        "        role = msg.get(\"role\", \"\").lower()\n",
        "        if role == \"system\":\n",
        "            continue\n",
        "        # Capitalize role for clarity.\n",
        "        role_display = \"User\" if role == \"user\" else \"Assistant\" if role == \"assistant\" else role.capitalize()\n",
        "        content = msg.get(\"content\", \"\").strip()\n",
        "        # Add each message as a paragraph.\n",
        "        doc.add_paragraph(f\"{role_display}: {content}\")\n",
        "    # Add a blank paragraph as separator between conversations.\n",
        "    doc.add_paragraph(\"\\n\")\n",
        "\n",
        "# Save the document.\n",
        "doc_output = \"non_successful_conversations.docx\"\n",
        "doc.save(doc_output)\n",
        "print(f\"Non-successful conversations saved to {doc_output}\")\n",
        "\n",
        "# --- Part 2: Extract and analyze the outlier conversation (87303 words) ---\n",
        "\n",
        "# Find the outlier conversation in df_non_success.\n",
        "outlier_df = df_non_success[df_non_success['dialogue_length'] == 87303]\n",
        "if outlier_df.empty:\n",
        "    print(\"No conversation with 87303 words found.\")\n",
        "else:\n",
        "    # Assume there's only one outlier; extract it.\n",
        "    outlier_conv = outlier_df.iloc[0]\n",
        "    outlier_id = outlier_conv['conversation_id']\n",
        "    print(f\"Outlier conversation found with ID: {outlier_id}\")\n",
        "\n",
        "    # Extract full text of the conversation (excluding system messages)\n",
        "    conv_text_parts = []\n",
        "    for msg in outlier_conv['messages']:\n",
        "        role = msg.get(\"role\", \"\").lower()\n",
        "        if role == \"system\":\n",
        "            continue\n",
        "        role_display = \"User\" if role == \"user\" else \"Assistant\" if role == \"assistant\" else role.capitalize()\n",
        "        content = msg.get(\"content\", \"\").strip()\n",
        "        conv_text_parts.append(f\"{role_display}: {content}\")\n",
        "    conv_text = \"\\n\\n\".join(conv_text_parts)\n",
        "\n",
        "    # Print basic analysis:\n",
        "    # Tokenize the text.\n",
        "    tokens = word_tokenize(conv_text.lower())\n",
        "    # Remove stopwords and punctuation.\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    punctuation = set(\".,!?;:\")\n",
        "    filtered_tokens = [t for t in tokens if t not in stop_words and t not in punctuation]\n",
        "\n",
        "    # Compute frequency distribution.\n",
        "    freq_dist = Counter(filtered_tokens)\n",
        "    most_common = freq_dist.most_common(10)\n",
        "\n",
        "    print(f\"\\nOutlier Conversation (ID: {outlier_id}) Analysis:\")\n",
        "    print(f\"Total words (after tokenization): {len(tokens)}\")\n",
        "    print(\"Top 10 most common words (excluding stopwords/punctuation):\")\n",
        "    for word, count in most_common:\n",
        "        print(f\"  {word}: {count}\")\n",
        "\n",
        "    # Optionally, you can save the outlier conversation text to a separate .txt file for further review.\n",
        "    with open(\"outlier_conversation.txt\", \"w\", encoding=\"utf-8\") as f_out:\n",
        "        f_out.write(conv_text)\n",
        "    print(\"Outlier conversation text saved to outlier_conversation.txt\")\n"
      ],
      "metadata": {
        "id": "pIOIJj0x5oPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c583f5-59b2-4c8f-bac5-8b5a9ad3a159"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-successful conversations saved to non_successful_conversations.docx\n",
            "Outlier conversation found with ID: 0\n",
            "\n",
            "Outlier Conversation (ID: 0) Analysis:\n",
            "Total words (after tokenization): 89953\n",
            "Top 10 most common words (excluding stopwords/punctuation):\n",
            "  team: 2383\n",
            "  *: 2332\n",
            "  member: 1482\n",
            "  's: 1182\n",
            "  help: 1174\n",
            "  thoughts: 1162\n",
            "  situation: 1161\n",
            "  conversation: 962\n",
            "  review: 934\n",
            "  user: 663\n",
            "Outlier conversation text saved to outlier_conversation.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example DataFrame structure:\n",
        "# Each row is a conversation with a 'messages' column containing a list of message dictionaries.\n",
        "# Example message: {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n",
        "\n",
        "def compute_turn_metrics(messages):\n",
        "    turn_count = 0\n",
        "    user_turns = 0\n",
        "    assistant_turns = 0\n",
        "    total_words = 0\n",
        "    words_per_turn = []\n",
        "\n",
        "    for msg in messages:\n",
        "        role = msg.get(\"role\", \"\").lower()\n",
        "        # Optionally, skip system messages:\n",
        "        if role == \"system\":\n",
        "            continue\n",
        "        turn_count += 1\n",
        "        if role == \"user\":\n",
        "            user_turns += 1\n",
        "        elif role == \"assistant\":\n",
        "            assistant_turns += 1\n",
        "\n",
        "        content = msg.get(\"content\", \"\")\n",
        "        tokens = word_tokenize(content)\n",
        "        word_count = len(tokens)\n",
        "        total_words += word_count\n",
        "        words_per_turn.append(word_count)\n",
        "\n",
        "    avg_turn_length = total_words / turn_count if turn_count > 0 else 0\n",
        "    return {\n",
        "        \"turn_count\": turn_count,\n",
        "        \"user_turns\": user_turns,\n",
        "        \"assistant_turns\": assistant_turns,\n",
        "        \"total_words\": total_words,\n",
        "        \"avg_turn_length\": avg_turn_length,\n",
        "        \"words_per_turn\": words_per_turn\n",
        "    }\n",
        "\n",
        "# Assuming df_conversations is your DataFrame with each conversation in a 'messages' column.\n",
        "df_conversations[\"turn_metrics\"] = df_conversations[\"messages\"].apply(compute_turn_metrics)\n",
        "\n",
        "# Example: Extract and display metrics for the 2nd conversation.\n",
        "first_metrics = df_conversations.iloc[1][\"turn_metrics\"]\n",
        "print('conversation #2')\n",
        "print(\"Turn count:\", first_metrics[\"turn_count\"])\n",
        "print(\"User turns:\", first_metrics[\"user_turns\"])\n",
        "print(\"Assistant turns:\", first_metrics[\"assistant_turns\"])\n",
        "print(\"Average turn length (words):\", first_metrics[\"avg_turn_length\"])\n"
      ],
      "metadata": {
        "id": "HisPbua75oS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef1a769-3f72-4902-d4b8-96d2a92998c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conversation #2\n",
            "Turn count: 31\n",
            "User turns: 16\n",
            "Assistant turns: 15\n",
            "Average turn length (words): 71.41935483870968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop over all conversations and print turn metrics\n",
        "for index, row in df_conversations.iterrows():\n",
        "    # Calculate metrics for the current conversation\n",
        "    metrics = compute_turn_metrics(row[\"messages\"])\n",
        "    conv_id = row.get(\"conversation_id\", index)\n",
        "\n",
        "    print(f\"Conversation {conv_id}:\")\n",
        "    print(f\"  Total Turns: {metrics['turn_count']}\")\n",
        "    print(f\"  User Turns: {metrics['user_turns']}\")\n",
        "    print(f\"  Assistant Turns: {metrics['assistant_turns']}\")\n",
        "    print(f\"  Total Words: {metrics['total_words']}\")\n",
        "    print(f\"  Average Turn Length: {metrics['avg_turn_length']:.2f} words\")\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "mBtDtTqm5oWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e5843e-f100-4909-a03d-050b94a792fe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation 0:\n",
            "  Total Turns: 1325\n",
            "  User Turns: 663\n",
            "  Assistant Turns: 662\n",
            "  Total Words: 87303\n",
            "  Average Turn Length: 65.89 words\n",
            "----------------------------------------\n",
            "Conversation 1:\n",
            "  Total Turns: 31\n",
            "  User Turns: 16\n",
            "  Assistant Turns: 15\n",
            "  Total Words: 2214\n",
            "  Average Turn Length: 71.42 words\n",
            "----------------------------------------\n",
            "Conversation 2:\n",
            "  Total Turns: 25\n",
            "  User Turns: 13\n",
            "  Assistant Turns: 12\n",
            "  Total Words: 1644\n",
            "  Average Turn Length: 65.76 words\n",
            "----------------------------------------\n",
            "Conversation 3:\n",
            "  Total Turns: 41\n",
            "  User Turns: 21\n",
            "  Assistant Turns: 20\n",
            "  Total Words: 4543\n",
            "  Average Turn Length: 110.80 words\n",
            "----------------------------------------\n",
            "Conversation 4:\n",
            "  Total Turns: 23\n",
            "  User Turns: 12\n",
            "  Assistant Turns: 11\n",
            "  Total Words: 1587\n",
            "  Average Turn Length: 69.00 words\n",
            "----------------------------------------\n",
            "Conversation 5:\n",
            "  Total Turns: 39\n",
            "  User Turns: 20\n",
            "  Assistant Turns: 19\n",
            "  Total Words: 2919\n",
            "  Average Turn Length: 74.85 words\n",
            "----------------------------------------\n",
            "Conversation 6:\n",
            "  Total Turns: 33\n",
            "  User Turns: 17\n",
            "  Assistant Turns: 16\n",
            "  Total Words: 3044\n",
            "  Average Turn Length: 92.24 words\n",
            "----------------------------------------\n",
            "Conversation 7:\n",
            "  Total Turns: 41\n",
            "  User Turns: 21\n",
            "  Assistant Turns: 20\n",
            "  Total Words: 2843\n",
            "  Average Turn Length: 69.34 words\n",
            "----------------------------------------\n",
            "Conversation 8:\n",
            "  Total Turns: 25\n",
            "  User Turns: 13\n",
            "  Assistant Turns: 12\n",
            "  Total Words: 1882\n",
            "  Average Turn Length: 75.28 words\n",
            "----------------------------------------\n",
            "Conversation 9:\n",
            "  Total Turns: 19\n",
            "  User Turns: 10\n",
            "  Assistant Turns: 9\n",
            "  Total Words: 1413\n",
            "  Average Turn Length: 74.37 words\n",
            "----------------------------------------\n",
            "Conversation 10:\n",
            "  Total Turns: 27\n",
            "  User Turns: 14\n",
            "  Assistant Turns: 13\n",
            "  Total Words: 2211\n",
            "  Average Turn Length: 81.89 words\n",
            "----------------------------------------\n",
            "Conversation 11:\n",
            "  Total Turns: 21\n",
            "  User Turns: 11\n",
            "  Assistant Turns: 10\n",
            "  Total Words: 1489\n",
            "  Average Turn Length: 70.90 words\n",
            "----------------------------------------\n",
            "Conversation 12:\n",
            "  Total Turns: 13\n",
            "  User Turns: 7\n",
            "  Assistant Turns: 6\n",
            "  Total Words: 1220\n",
            "  Average Turn Length: 93.85 words\n",
            "----------------------------------------\n",
            "Conversation 13:\n",
            "  Total Turns: 23\n",
            "  User Turns: 12\n",
            "  Assistant Turns: 11\n",
            "  Total Words: 1838\n",
            "  Average Turn Length: 79.91 words\n",
            "----------------------------------------\n",
            "Conversation 14:\n",
            "  Total Turns: 43\n",
            "  User Turns: 22\n",
            "  Assistant Turns: 21\n",
            "  Total Words: 3762\n",
            "  Average Turn Length: 87.49 words\n",
            "----------------------------------------\n",
            "Conversation 15:\n",
            "  Total Turns: 35\n",
            "  User Turns: 18\n",
            "  Assistant Turns: 17\n",
            "  Total Words: 2200\n",
            "  Average Turn Length: 62.86 words\n",
            "----------------------------------------\n",
            "Conversation 16:\n",
            "  Total Turns: 27\n",
            "  User Turns: 14\n",
            "  Assistant Turns: 13\n",
            "  Total Words: 1934\n",
            "  Average Turn Length: 71.63 words\n",
            "----------------------------------------\n",
            "Conversation 17:\n",
            "  Total Turns: 33\n",
            "  User Turns: 17\n",
            "  Assistant Turns: 16\n",
            "  Total Words: 1699\n",
            "  Average Turn Length: 51.48 words\n",
            "----------------------------------------\n",
            "Conversation 18:\n",
            "  Total Turns: 15\n",
            "  User Turns: 8\n",
            "  Assistant Turns: 7\n",
            "  Total Words: 1369\n",
            "  Average Turn Length: 91.27 words\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Turn Balance:**\n",
        "Most conversations show a balanced turn distribution between the user and the assistant. For instance, in almost every dialogue, the number of user turns and assistant turns is almost equal, which may indicate that both parties are engaged in a back-and-forth exchange. This balance could be a positive indicator of a collaborative conversation.\n",
        "\n",
        "**Conversation Length Variation:**\n",
        "The total turn counts vary widely—from as few as 13 turns (Conversation 12) to as many as 43 turns (Conversation 14). Longer conversations (in terms of turns or total words) might suggest more in‑depth or complex discussions, while shorter ones could be more straightforward or focused.\n",
        "\n",
        "**Average Turn Length Differences:**\n",
        "Average turn lengths range from about 51 words (Conversation 17) to over 110 words (Conversation 3). Longer turns may *indicate more detailed or explanatory responses*, whereas shorter turns might be more to the point.\n",
        "\n",
        "For example, **Conversation 3**’s higher average (110.80 words per turn) could reflect a more elaborative or detailed exchange, perhaps tackling a more nuanced issue.\n",
        "In contrast, **Conversation 17**’s lower average (51.48 words per turn) might suggest a brisk, succinct conversation style.\n",
        "\n",
        "**Implications for Dialogue Quality:**\n",
        "A balanced turn-taking structure generally indicates that both sides are contributing. However, whether longer or shorter turns lead to higher user satisfaction **might depend on the context**:\n",
        "\n",
        "In some situations, concise answers (shorter turns) could be preferred for efficiency.\n",
        "In other contexts, more detailed answers (longer turns) might be necessary to cover complex topics.\n",
        "\n",
        "**Potential for Further Analysis:**\n",
        "It could be useful to correlate these turn metrics with other factors (e.g., user feedback or outcome measures) to see if, for example, conversations with a particular range of average turn lengths tend to be rated more highly. Also, analyzing whether longer conversations tend to be more engaging or if they sometimes indicate over-elaboration could provide deeper insights."
      ],
      "metadata": {
        "id": "50UPSgXc1Bpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Analyzing conversation #3**\n",
        "with the highest average words per turn\n",
        "\n",
        "**Summary**:\n",
        "\n",
        "In this conversation, the user prepares for a difficult discussion with a client. The context is that the user's team is undergoing a restructuring—because the business is moving to a more cost‑effective country, the team needs to meet a specific Leader-to-team member ratio, which now renders one Leader surplus. The user explains that one Leader, who has demonstrated strong technical skills and contributed significantly to the team, might be re‑assigned to a new role. However, the client is known to be extremely cost‑focused and numbers‑oriented and is new to this line of business, meaning that trust hasn’t been fully established yet.\n",
        "\n",
        "Throughout the conversation, the assistant guides the user in clarifying not only the factual background (such as the current ratio and the observed technical proficiency) but also the deeper concerns and unexpressed feelings. The user reveals internal conflicts: on one hand, a sense of responsibility to advocate for the team and explore all options for retaining valuable talent; on the other, a worry about being perceived as misaligned with the client’s cost‑cutting strategy or as incompetent. The conversation delves into these layers, touching on the user's values around human‑centric leadership, professional integrity, and the importance of business continuity. The assistant helps the user outline both the context and an example dialogue, and later assists in outlining a pilot proposal to test the new role’s value while addressing cost concerns.\n",
        "\n",
        "**Conclusions and Relevance:**\n",
        "\n",
        "**Depth of Analysis:**\n",
        "The conversation is highly relevant because it not only captures the logistical challenges (such as the need to adjust team ratios) but also deeply explores the emotional and value‑based dimensions of the issue. The assistant’s probing questions help the user articulate both the observable facts and the underlying concerns—key elements when preparing for a strategic conversation with a cost‑focused client.\n",
        "\n",
        "**Balanced Perspective**:\n",
        "The dialogue shows that the user is trying to balance two important objectives: honoring the client's financial priorities while ensuring that valuable team capabilities aren’t lost. This balance is essential for maintaining business continuity and strategic alignment. The conversation’s structure highlights the importance of empathy, active listening, and finding common ground—critical skills in challenging negotiations.\n",
        "\n",
        "**Actionable Outcome**:\n",
        "The discussion culminates in concrete next steps, such as drafting a pilot proposal with clear KPIs. By outlining a proposal that includes an initial assessment, a pilot phase, and regular reviews, the conversation directly supports the user in taking a data‑driven, measured approach that could mitigate risks associated with both talent loss and client cost concerns.\n",
        "\n",
        "**Relevance to Business Strategy**:\n",
        "Given that the client’s priorities are sharply focused on cost reduction, the conversation’s detailed exploration of how to demonstrate value (e.g., through efficiency gains and strategic role re‑assignment) is particularly pertinent. It ensures that the user's approach is aligned with both the emotional needs of the team and the practical, financial demands of the client.\n",
        "\n",
        "**Overall**, Conversation #3 is an excellent example of using a structured, reflective approach to prepare for a difficult conversation. It demonstrates how combining objective data with an exploration of personal values and concerns can lead to a more effective, nuanced strategy that addresses both internal and external stakeholder needs."
      ],
      "metadata": {
        "id": "RgiBdIJi8UQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain"
      ],
      "metadata": {
        "id": "j8z0ohC_J-Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai pandas"
      ],
      "metadata": {
        "id": "rlSLq_0Q5oak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7a471cef-a4fb-42f9-dc42-99d2173826f7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain langchain-community langchain-openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVeAnBG1VD_I",
        "outputId": "03c2b8b1-25b0-44db-cc92-d106de79ee2d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting openai<2.0.0,>=1.66.3 (from langchain-openai)\n",
            "  Downloading openai-1.66.5-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.9-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
            "Downloading openai-1.66.5-py3-none-any.whl (571 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.1/571.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, pydantic-settings, openai, dataclasses-json, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.6\n",
            "    Uninstalling langchain-text-splitters-0.3.6:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.6\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.20\n",
            "    Uninstalling langchain-0.3.20:\n",
            "      Successfully uninstalled langchain-0.3.20\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.21 langchain-community-0.3.19 langchain-openai-0.3.9 langchain-text-splitters-0.3.7 marshmallow-3.26.1 mypy-extensions-1.0.0 openai-1.66.5 pydantic-settings-2.8.1 python-dotenv-1.0.1 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(dir(langchain))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2lSr7-wUl2O",
        "outputId": "a9da77d0-c578-49ec-fb67-a4da8d7d13c3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Any', 'Optional', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__getattr__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_warn_on_import', 'surface_langchain_deprecation_warnings', 'warnings']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "import re"
      ],
      "metadata": {
        "id": "4x6Q-xqhBne3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\" # Replace with actual key!"
      ],
      "metadata": {
        "id": "h0Prae_jTa3d"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversations = []\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            conversations.append(json.loads(line.strip()))\n",
        "        except json.JSONDecodeError:\n",
        "            continue  # Skip invalid lines\n",
        "\n",
        "# Extract relevant data\n",
        "\n",
        "data_list = []\n",
        "for convo in conversations:\n",
        "    messages = convo.get(\"inputs\", {}).get(\"messages\", [])\n",
        "\n",
        "    # Extract user messages\n",
        "    user_messages = [msg[\"content\"] for msg in messages if msg[\"role\"] == \"user\"]\n",
        "\n",
        "    # Extract feedback correctly\n",
        "    feedback_messages = [msg for msg in user_messages if any(\n",
        "        kw in msg.lower() for kw in [\"satisfactory\", \"helpful\", \"useful\", \"positive\", \"negative\"]\n",
        "    )]\n",
        "\n",
        "    # Store extracted information\n",
        "    data_list.append({\n",
        "        \"user_messages\": \" \".join(user_messages),  # Combine all user messages for LLM input\n",
        "        \"feedback_messages\": \" \".join(feedback_messages),\n",
        "    })\n",
        "\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data_list)\n",
        "\n",
        "# Initialize LangChain LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\")\n"
      ],
      "metadata": {
        "id": "QFFXNxnuTfT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to categorize conversations and extract trends\n",
        "def analyze_conversation(convo_text):\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following conversation and categorize it into a main theme (e.g., \"Conflict Resolution\", \"Leadership Coaching\", \"Feedback Handling\").\n",
        "    Also, determine the user's satisfaction level based on their feedback.\n",
        "\n",
        "    Conversation:\n",
        "    {convo_text}\n",
        "\n",
        "    Return the result in JSON format with:\n",
        "    - \"category\": The conversation theme\n",
        "    - \"satisfaction\": \"High\", \"Medium\", or \"Low\"\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)]).content\n",
        "\n",
        "    # Fix: Remove markdown formatting (backticks) from JSON response\n",
        "    clean_response = re.sub(r\"```json\\n|\\n```\", \"\", response).strip()\n",
        "\n",
        "    # Handle empty or malformed responses\n",
        "    try:\n",
        "        return json.loads(clean_response)  # Convert response to dictionary\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Warning: LLM returned an unparseable response:\\n{response}\\n\")\n",
        "        return {\"category\": \"Unknown\", \"satisfaction\": \"Unknown\"}  # Default fallback\n",
        "\n",
        "\n",
        "# Apply AI analysis to each conversation\n",
        "df[\"analysis\"] = df[\"user_messages\"].apply(analyze_conversation)\n",
        "\n",
        "# Extract structured results\n",
        "df[\"category\"] = df[\"analysis\"].apply(lambda x: x.get(\"category\", \"Unknown\"))\n",
        "df[\"satisfaction\"] = df[\"analysis\"].apply(lambda x: x.get(\"satisfaction\", \"Unknown\"))\n",
        "\n",
        "# Save processed data\n",
        "df.to_csv(\"conversation_analysis_results.csv\", index=False)\n",
        "\n",
        "# Display results\n",
        "print(df.head())\n",
        "\n",
        "# Group by category to analyze trends\n",
        "category_trends = df.groupby(\"category\")[\"satisfaction\"].value_counts(normalize=True).unstack()\n",
        "\n",
        "# Display trends in satisfaction across categories\n",
        "print(\"\\nUser Satisfaction Trends by Conversation Type:\")\n",
        "print(category_trends)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHZ06JP3VnFa",
        "outputId": "43093ca1-c47a-4456-e178-80672dba6d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       user_messages  \\\n",
            "0  Review a difficult conversation I already had ...   \n",
            "1  Prepare for a difficult conversation I am goin...   \n",
            "2  Review a difficult conversation I already had ...   \n",
            "3  Prepare for a difficult conversation I am goin...   \n",
            "4  Review a difficult conversation I already had ...   \n",
            "\n",
            "                                   feedback_messages  \\\n",
            "0  THere is a team member in my team who is alway...   \n",
            "1  The goal of the training is the leadership dev...   \n",
            "2                                  very satisfactory   \n",
            "3                very satisfactory extremely helpful   \n",
            "4                                  very satisfactory   \n",
            "\n",
            "                                            analysis             category  \\\n",
            "0  {'category': 'Conflict Resolution', 'satisfact...  Conflict Resolution   \n",
            "1  {'category': 'Conflict Resolution', 'satisfact...  Conflict Resolution   \n",
            "2  {'category': 'Feedback Handling', 'satisfactio...    Feedback Handling   \n",
            "3  {'category': 'Conflict Resolution', 'satisfact...  Conflict Resolution   \n",
            "4  {'category': 'Conflict Resolution', 'satisfact...  Conflict Resolution   \n",
            "\n",
            "  satisfaction  \n",
            "0          Low  \n",
            "1         High  \n",
            "2         High  \n",
            "3         High  \n",
            "4         High  \n",
            "\n",
            "User Satisfaction Trends by Conversation Type:\n",
            "satisfaction                                  High       Low    Medium\n",
            "category                                                              \n",
            "Career Development and Feedback Handling  1.000000       NaN       NaN\n",
            "Conflict Resolution                       0.538462  0.384615  0.076923\n",
            "Feedback Handling                         0.400000  0.200000  0.400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category_trends.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "y9669SVrBnk-",
        "outputId": "3801259f-dcf6-4749-db78-3b3735067484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'category_trends' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-50c3fb3d4a5b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategory_trends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'category_trends' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### further attempts to play with it"
      ],
      "metadata": {
        "id": "th9qZhvfcPRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation import l.oad_evaluator\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage"
      ],
      "metadata": {
        "id": "Au_kwo6KBnqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
        "\n",
        "evaluator = load_evaluator(\n",
        "    \"criteria\",\n",
        "    llm=llm,\n",
        "    criteria={\n",
        "        \"conciseness\": \"Is the response short and to the point while still being informative?\",\n",
        "        \"relevance\": \"Does the response directly address the user's question?\",\n",
        "        \"helpfulness\": \"Does the response provide meaningful and useful information?\",\n",
        "        \"completeness\": \"Is the response sufficiently detailed and does it cover all aspects of the query?\"\n",
        "    }\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "_cTeOvDDBnv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = []\n",
        "for convo in conversations:\n",
        "    messages = convo.get(\"inputs\", {}).get(\"messages\", [])\n",
        "\n",
        "    # Extract user & assistant messages\n",
        "    user_messages = [msg[\"content\"] for msg in messages if msg.get(\"role\") == \"user\"]\n",
        "    assistant_messages = [msg[\"content\"] for msg in messages if msg.get(\"role\") == \"assistant\"]\n",
        "\n",
        "    # Skip evaluation if assistant response is missing\n",
        "    if not assistant_messages:\n",
        "        continue\n",
        "\n",
        "    # Select last assistant response for evaluation\n",
        "    ai_response = assistant_messages[-1]\n",
        "    user_input = user_messages[-1] if user_messages else \"\"\n",
        "\n",
        "    # Evaluate AI response using LangChain\n",
        "    eval_result = evaluator.evaluate_strings(\n",
        "        prediction=ai_response,\n",
        "        input=user_input\n",
        "    )\n",
        "\n",
        "    # Store structured results\n",
        "    evaluation_results.append({\n",
        "        \"user_input\": user_input,\n",
        "        \"ai_response\": ai_response,\n",
        "        \"evaluation\": eval_result\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "df_evaluation = pd.DataFrame(evaluation_results)\n",
        "df_evaluation.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "pRECkfZkBn1O",
        "outputId": "3ef6e756-9e5e-40d2-e0fe-77b63620286d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          user_input  \\\n",
              "0  THere is a team member in my team who is alway...   \n",
              "1                                            thanks!   \n",
              "2                                        good night!   \n",
              "3                        looks good. Thank you again   \n",
              "4        I dont know what else to ask :) it was fine   \n",
              "\n",
              "                                         ai_response  \\\n",
              "0  Thank you for sharing more about the situation...   \n",
              "1  Thank you for your kind feedback! I'm glad you...   \n",
              "2  No worries at all! I'm glad to hear that your ...   \n",
              "3  Great to hear that the conversation example wo...   \n",
              "4  I'm really pleased to hear that it helped! \\n\\...   \n",
              "\n",
              "                                          evaluation  \n",
              "0  {'reasoning': 'To assess whether the submissio...  \n",
              "1  {'reasoning': 'To assess whether the submissio...  \n",
              "2  {'reasoning': 'To evaluate whether the submiss...  \n",
              "3  {'reasoning': '**Conciseness:**  \n",
              "1. The submi...  \n",
              "4  {'reasoning': 'To evaluate whether the submiss...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05d11874-cf4b-473e-b6a3-fc296f9ec9bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>ai_response</th>\n",
              "      <th>evaluation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THere is a team member in my team who is alway...</td>\n",
              "      <td>Thank you for sharing more about the situation...</td>\n",
              "      <td>{'reasoning': 'To assess whether the submissio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thanks!</td>\n",
              "      <td>Thank you for your kind feedback! I'm glad you...</td>\n",
              "      <td>{'reasoning': 'To assess whether the submissio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>good night!</td>\n",
              "      <td>No worries at all! I'm glad to hear that your ...</td>\n",
              "      <td>{'reasoning': 'To evaluate whether the submiss...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>looks good. Thank you again</td>\n",
              "      <td>Great to hear that the conversation example wo...</td>\n",
              "      <td>{'reasoning': '**Conciseness:**  \n",
              "1. The submi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I dont know what else to ask :) it was fine</td>\n",
              "      <td>I'm really pleased to hear that it helped! \\n\\...</td>\n",
              "      <td>{'reasoning': 'To evaluate whether the submiss...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05d11874-cf4b-473e-b6a3-fc296f9ec9bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05d11874-cf4b-473e-b6a3-fc296f9ec9bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05d11874-cf4b-473e-b6a3-fc296f9ec9bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-846b3e5b-32b5-44b1-affd-d3a0a4168f73\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-846b3e5b-32b5-44b1-affd-d3a0a4168f73')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-846b3e5b-32b5-44b1-affd-d3a0a4168f73 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_evaluation",
              "summary": "{\n  \"name\": \"df_evaluation\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"THere is a team member in my team who is always negative. Every new initiative is stupid, everything new is bad, everything old is amazing. There is never any solution for the problems. In the end she performs exceptionally well but her attitude is infectious in a negative way\",\n          \"no thank youy\",\n          \"i am clear about the aproach, acknowledging her thoughts but clarifiying the importance of following correct documentation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ai_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Thank you for sharing more about the situation. It sounds like you're dealing with a challenging team dynamic where a team member's negativity is impacting the overall morale, despite their strong performance.\\n\\nTo help you review the conversation, let's explore the unexpressed thoughts and feelings you had during these interactions. What were you thinking or feeling but not saying during your conversations with this team member? This will help us understand the underlying emotions and thoughts that might be influencing the situation. Feel free to share any specific moments or examples that stand out to you.\",\n          \"That's a great question. Managing emotions and frustration during a difficult conversation can be challenging but is crucial for maintaining a productive and respectful dialogue. Here are a few strategies to help you stay calm and focused:\\n\\n1. **Prepare and Practice:** Before the meeting, take some time to practice what you want to say. This can help you feel more confident and less emotional. You can even practice with a trusted colleague or friend to get feedback.\\n\\n2. **Focus on Facts and Solutions:** As we've discussed, separating facts from thoughts can help you stay grounded. Stick to the observable facts and focus on finding solutions rather than dwelling on the problems.\\n\\n3. **Use \\\"I\\\" Statements:** Frame your concerns using \\\"I\\\" statements to express how the situation impacts you without sounding accusatory. For example, \\\"I feel unprepared when the process isn't followed, and it affects my ability to manage my workload effectively.\\\"\\n\\n4. **Take Deep Breaths:** If you start to feel overwhelmed or frustrated during the conversation, take a few deep breaths to calm yourself. This can help you regain composure and think more clearly.\\n\\n5. **Stay Open and Curious:** Approach the conversation with a mindset of curiosity and openness. Ask questions to understand the other person's perspective and show that you are willing to collaborate on finding a solution.\\n\\n6. **Pause if Needed:** If emotions start to run high, it's okay to suggest a brief pause. You can say something like, \\\"I think we all need a moment to gather our thoughts. Can we take a short break and then continue?\\\"\\n\\nWould you like to practice any specific part of the conversation or explore any of these strategies further?\",\n          \"Great! Now let's focus on how to have a productive conversation and understand the other person's perspective. This involves sharing your thoughts openly while staying receptive to the other person's views.\\n\\nOne key aspect is active listening. This means fully concentrating on what Andrea is saying, acknowledging her points, and responding thoughtfully. It helps to paraphrase what she says to show you understand and to clarify any misunderstandings.\\n\\nFor example, if Andrea says, \\\"I had those conversations multiple times, and I thought that was enough,\\\" you might respond with, \\\"I hear you saying that you've had these conversations multiple times and believed that was sufficient. I understand that, but the documentation is essential for us to proceed with any formal actions.\\\"\\n\\nThis approach shows that you value her perspective while also clearly stating your own concerns.\\n\\nWould you like to practice this kind of dialogue, or do you have any specific questions about how to stay receptive and share your thoughts openly?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evaluation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract key evaluation details into a structured format\n",
        "evaluation_data = []\n",
        "\n",
        "for index, row in df_evaluation.iterrows():\n",
        "    eval_result = row[\"evaluation\"]\n",
        "\n",
        "    # Extract details if available\n",
        "    reasoning = eval_result.get(\"reasoning\", \"N/A\")  # Full explanation\n",
        "    value = eval_result.get(\"value\", \"N/A\")  # Pass/Fail/Other criteria\n",
        "    score = eval_result.get(\"score\", None)  # Numeric Score\n",
        "\n",
        "    # Store structured data\n",
        "    evaluation_data.append({\n",
        "        \"user_input\": row[\"user_input\"],\n",
        "        \"ai_response\": row[\"ai_response\"],\n",
        "        \"reasoning\": reasoning,\n",
        "        \"value\": value,\n",
        "        \"score\": score\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame for easy visualization\n",
        "df_structured_eval = pd.DataFrame(evaluation_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "wV40kSiOhM12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_structured_eval['value'].value_counts(), df_structured_eval['score'].value_counts() # score is 0-1 (binary classified)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUNsiinthM5L",
        "outputId": "a5c45565-d539-4deb-ff69-55da010ee3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(value\n",
              " N    17\n",
              " Y     2\n",
              " Name: count, dtype: int64,\n",
              " score\n",
              " 0    17\n",
              " 1     2\n",
              " Name: count, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#switching to 10-scale\n",
        "evaluator = load_evaluator(\n",
        "    \"criteria\",\n",
        "    llm=llm,\n",
        "    criteria={\n",
        "        \"conciseness\": \"Rate on a scale of 0-10. Is the response short and to the point while still being informative?\",\n",
        "        \"relevance\": \"Rate on a scale of 0-10. Does the response directly address the user's question?\",\n",
        "        \"helpfulness\": \"Rate on a scale of 0-10. Does the response provide meaningful and useful information?\",\n",
        "        \"completeness\": \"Rate on a scale of 0-10. Is the response sufficiently detailed and does it cover all aspects of the query?\"\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "Lru_O-zfhM8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = []\n",
        "\n",
        "for convo in conversations:\n",
        "    messages = convo.get(\"inputs\", {}).get(\"messages\", [])\n",
        "\n",
        "    # Extract user & assistant messages\n",
        "    user_messages = [msg[\"content\"] for msg in messages if msg.get(\"role\") == \"user\"]\n",
        "    assistant_messages = [msg[\"content\"] for msg in messages if msg.get(\"role\") == \"assistant\"]\n",
        "\n",
        "    # Skip evaluation if assistant response is missing\n",
        "    if not assistant_messages:\n",
        "        continue\n",
        "\n",
        "    # Select last assistant response for evaluation\n",
        "    ai_response = assistant_messages[-1]\n",
        "    user_input = user_messages[-1] if user_messages else \"\"\n",
        "\n",
        "    # Evaluate AI response using LangChain\n",
        "    eval_result = evaluator.evaluate_strings(\n",
        "        prediction=ai_response,\n",
        "        input=user_input\n",
        "    )\n",
        "\n",
        "    # Extract structured evaluation details\n",
        "    evaluation_results.append({\n",
        "        \"user_input\": user_input,\n",
        "        \"ai_response\": ai_response,\n",
        "        \"conciseness_score\": eval_result.get(\"conciseness\", {}).get(\"score\", \"N/A\"),\n",
        "        \"relevance_score\": eval_result.get(\"relevance\", {}).get(\"score\", \"N/A\"),\n",
        "        \"helpfulness_score\": eval_result.get(\"helpfulness\", {}).get(\"score\", \"N/A\"),\n",
        "        \"completeness_score\": eval_result.get(\"completeness\", {}).get(\"score\", \"N/A\"),\n",
        "        \"reasoning\": eval_result.get(\"reasoning\", \"N/A\")  # Store evaluation explanation\n",
        "    })\n",
        "\n",
        "df_evaluation = pd.DataFrame(evaluation_results)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8G5V7ex2lOhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract key evaluation details into a structured format\n",
        "evaluation_data = []\n",
        "\n",
        "for index, row in df_evaluation.iterrows():\n",
        "    eval_result = row[\"evaluation\"]\n",
        "\n",
        "    # Extract main reasoning, score, and value\n",
        "    reasoning = eval_result.get(\"reasoning\", \"N/A\")\n",
        "    value = eval_result.get(\"value\", \"N/A\")\n",
        "    overall_score = eval_result.get(\"score\", \"N/A\")  # Numeric score\n",
        "\n",
        "    # Extract individual criterion scores (if available in reasoning)\n",
        "    conciseness_score = None\n",
        "    relevance_score = None\n",
        "    helpfulness_score = None\n",
        "    completeness_score = None\n",
        "\n",
        "    # Manually parse reasoning to extract scores\n",
        "    if \"conciseness\" in reasoning.lower():\n",
        "        conciseness_score = overall_score  # Placeholder (we need a better way to parse this)\n",
        "    if \"relevance\" in reasoning.lower():\n",
        "        relevance_score = overall_score\n",
        "    if \"helpfulness\" in reasoning.lower():\n",
        "        helpfulness_score = overall_score\n",
        "    if \"completeness\" in reasoning.lower():\n",
        "        completeness_score = overall_score\n",
        "\n",
        "    # Store structured data\n",
        "    evaluation_data.append({\n",
        "        \"user_input\": row[\"user_input\"],\n",
        "        \"ai_response\": row[\"ai_response\"],\n",
        "        \"conciseness_score\": conciseness_score,\n",
        "        \"relevance_score\": relevance_score,\n",
        "        \"helpfulness_score\": helpfulness_score,\n",
        "        \"completeness_score\": completeness_score,\n",
        "        \"overall_score\": overall_score,\n",
        "        \"value\": value,\n",
        "        \"reasoning\": reasoning\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame for easy visualization\n",
        "df_structured_eval = pd.DataFrame(evaluation_data)\n"
      ],
      "metadata": {
        "id": "QxdC1wW-l-1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_structured_eval.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cNA2gYxllUAO",
        "outputId": "96e8843d-2e88-4f84-cb9b-5ac1715e73f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          user_input  \\\n",
              "0  THere is a team member in my team who is alway...   \n",
              "1                                            thanks!   \n",
              "2                                        good night!   \n",
              "3                        looks good. Thank you again   \n",
              "4        I dont know what else to ask :) it was fine   \n",
              "\n",
              "                                         ai_response  conciseness_score  \\\n",
              "0  Thank you for sharing more about the situation...                  0   \n",
              "1  Thank you for your kind feedback! I'm glad you...                  0   \n",
              "2  No worries at all! I'm glad to hear that your ...                  0   \n",
              "3  Great to hear that the conversation example wo...                  1   \n",
              "4  I'm really pleased to hear that it helped! \\n\\...                  0   \n",
              "\n",
              "   relevance_score  helpfulness_score  completeness_score  overall_score  \\\n",
              "0                0                  0                   0              0   \n",
              "1                0                  0                   0              0   \n",
              "2                0                  0                   0              0   \n",
              "3                1                  1                   1              1   \n",
              "4                0                  0                   0              0   \n",
              "\n",
              "  value                                          reasoning  \n",
              "0     N  To assess whether the submission meets all the...  \n",
              "1     N  To assess whether the submission meets the cri...  \n",
              "2     N  To evaluate whether the submission meets all t...  \n",
              "3     Y  **Conciseness:**  \\n1. The submission is relat...  \n",
              "4     N  To evaluate whether the submission meets the c...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90f4f7d9-e0de-438c-a9d6-ea927448abe8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>ai_response</th>\n",
              "      <th>conciseness_score</th>\n",
              "      <th>relevance_score</th>\n",
              "      <th>helpfulness_score</th>\n",
              "      <th>completeness_score</th>\n",
              "      <th>overall_score</th>\n",
              "      <th>value</th>\n",
              "      <th>reasoning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THere is a team member in my team who is alway...</td>\n",
              "      <td>Thank you for sharing more about the situation...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>To assess whether the submission meets all the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thanks!</td>\n",
              "      <td>Thank you for your kind feedback! I'm glad you...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>To assess whether the submission meets the cri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>good night!</td>\n",
              "      <td>No worries at all! I'm glad to hear that your ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>To evaluate whether the submission meets all t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>looks good. Thank you again</td>\n",
              "      <td>Great to hear that the conversation example wo...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Y</td>\n",
              "      <td>**Conciseness:**  \\n1. The submission is relat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I dont know what else to ask :) it was fine</td>\n",
              "      <td>I'm really pleased to hear that it helped! \\n\\...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>To evaluate whether the submission meets the c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90f4f7d9-e0de-438c-a9d6-ea927448abe8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90f4f7d9-e0de-438c-a9d6-ea927448abe8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90f4f7d9-e0de-438c-a9d6-ea927448abe8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13f7d107-7eee-4be3-9ad3-81c7c5cb8d43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13f7d107-7eee-4be3-9ad3-81c7c5cb8d43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13f7d107-7eee-4be3-9ad3-81c7c5cb8d43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_structured_eval",
              "summary": "{\n  \"name\": \"df_structured_eval\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"THere is a team member in my team who is always negative. Every new initiative is stupid, everything new is bad, everything old is amazing. There is never any solution for the problems. In the end she performs exceptionally well but her attitude is infectious in a negative way\",\n          \"no thank youy\",\n          \"i am clear about the aproach, acknowledging her thoughts but clarifiying the importance of following correct documentation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ai_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Thank you for sharing more about the situation. It sounds like you're dealing with a challenging team dynamic where a team member's negativity is impacting the overall morale, despite their strong performance.\\n\\nTo help you review the conversation, let's explore the unexpressed thoughts and feelings you had during these interactions. What were you thinking or feeling but not saying during your conversations with this team member? This will help us understand the underlying emotions and thoughts that might be influencing the situation. Feel free to share any specific moments or examples that stand out to you.\",\n          \"That's a great question. Managing emotions and frustration during a difficult conversation can be challenging but is crucial for maintaining a productive and respectful dialogue. Here are a few strategies to help you stay calm and focused:\\n\\n1. **Prepare and Practice:** Before the meeting, take some time to practice what you want to say. This can help you feel more confident and less emotional. You can even practice with a trusted colleague or friend to get feedback.\\n\\n2. **Focus on Facts and Solutions:** As we've discussed, separating facts from thoughts can help you stay grounded. Stick to the observable facts and focus on finding solutions rather than dwelling on the problems.\\n\\n3. **Use \\\"I\\\" Statements:** Frame your concerns using \\\"I\\\" statements to express how the situation impacts you without sounding accusatory. For example, \\\"I feel unprepared when the process isn't followed, and it affects my ability to manage my workload effectively.\\\"\\n\\n4. **Take Deep Breaths:** If you start to feel overwhelmed or frustrated during the conversation, take a few deep breaths to calm yourself. This can help you regain composure and think more clearly.\\n\\n5. **Stay Open and Curious:** Approach the conversation with a mindset of curiosity and openness. Ask questions to understand the other person's perspective and show that you are willing to collaborate on finding a solution.\\n\\n6. **Pause if Needed:** If emotions start to run high, it's okay to suggest a brief pause. You can say something like, \\\"I think we all need a moment to gather our thoughts. Can we take a short break and then continue?\\\"\\n\\nWould you like to practice any specific part of the conversation or explore any of these strategies further?\",\n          \"Great! Now let's focus on how to have a productive conversation and understand the other person's perspective. This involves sharing your thoughts openly while staying receptive to the other person's views.\\n\\nOne key aspect is active listening. This means fully concentrating on what Andrea is saying, acknowledging her points, and responding thoughtfully. It helps to paraphrase what she says to show you understand and to clarify any misunderstandings.\\n\\nFor example, if Andrea says, \\\"I had those conversations multiple times, and I thought that was enough,\\\" you might respond with, \\\"I hear you saying that you've had these conversations multiple times and believed that was sufficient. I understand that, but the documentation is essential for us to proceed with any formal actions.\\\"\\n\\nThis approach shows that you value her perspective while also clearly stating your own concerns.\\n\\nWould you like to practice this kind of dialogue, or do you have any specific questions about how to stay receptive and share your thoughts openly?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conciseness_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"helpfulness_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"completeness_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overall_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reasoning\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"To assess whether the submission meets all the criteria listed, let's evaluate each criterion step-by-step:\\n\\n1. **Conciseness**: \\n   - The response isn't particularly concise. It includes a detailed suggestion to explore unexpressed thoughts and feelings, which, while potentially useful, might be more elaborate than necessary given the input. The response could have been shortened by omitting some exploratory questions or directly suggesting a simple solution.\\n\\n2. **Relevance**: \\n   - The response attempts to address the broader issue of managing negativity within a team. However, the original input does not explicitly ask for assistance or advice, but rather describes a situation. While relevance could be interpreted broadly in terms of addressing the challenge posed, the response doesn't directly address any specific query, because none was stated in the input.\\n\\n3. **Helpfulness**: \\n   - The response offers a somewhat helpful approach by encouraging reflection on unexpressed thoughts and feelings, which can be a valuable exercise in understanding team dynamics. However, the usefulness might be limited as it does not provide actionable steps for dealing with the team member's negativity directly.\\n\\n4. **Completeness**:\\n   - The response is not entirely complete in its coverage as it does not offer direct advice or multiple strategies for addressing the negativity issue within the team. While it aims to create an understanding of the emotional undercurrents, it does not provide a comprehensive solution or guidance.\\n\\nUpon considering each criterion, the submission fails to fully meet the criteria due to issues primarily with conciseness, relevance, and completeness.\\n\\nN\",\n          \"To assess whether the submission meets the criteria on conciseness, relevance, helpfulness, and completeness, let's break it down step by step:\\n\\n**Conciseness:** \\n- The response is relatively detailed and offers several strategies for managing emotions during a difficult conversation. This means it is informative. However, the length could be considered excessive given the brevity of the input \\\"no thank youy,\\\" which does not clearly indicate a need for such a comprehensive response. Therefore, in terms of conciseness, the response is not short and to the point relative to the vague prompt provided.\\n\\n**Relevance:** \\n- The input \\\"no thank youy\\\" lacks context, making it difficult to discern a clear question or subject matter to address. The response assumes a context related to emotional management during conversations, which might not address the user's needs appropriately. While the response is relevant to a topic of managing conversations, it does not directly address the user's input, which makes it fail in terms of relevance.\\n\\n**Helpfulness:** \\n- The response provides useful strategies for managing emotions and handling difficult conversations. These strategies are practical and thoughtful, which makes the response potentially helpful if the context were indeed related to the topic addressed. However, without knowing if this topic is pertinent to the user's needs, its usefulness is reduced.\\n\\n**Completeness:** \\n- The response is comprehensive in offering multiple strategies for emotional management during conversations, addressing several aspects of the topic it assumes to be relevant. Consequently, it is complete but only in the context it imagined, which does not match the user-provided input.\\n\\nAfter evaluating the criteria, it becomes apparent that while the response could be seen as helpful and complete under an assumed context, it overall fails to meet the criteria because it does not address a directly stated question or concern due to lack of context in the input. Thus, the criteria of conciseness, relevance, and context-driven helpfulness are not fully met given the minimalistic and vague input provided.\\n\\nN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_structured_eval['overall_score'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "a3VwNyBfnjEV",
        "outputId": "4e3b6f6f-3dcd-4a57-be2c-e1a241d3c665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "overall_score\n",
              "0    17\n",
              "1     2\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>overall_score</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check evaluator response for multiple cases\n",
        "for i in range(3):  # Print first 3 evaluations\n",
        "    print(f\"\\n🔹 Evaluation {i+1}:\")\n",
        "    print(json.dumps(df_evaluation['evaluation'][i], indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vfl4hYymNkY",
        "outputId": "d2d7375d-6704-49c5-f76c-fe4909fd77c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Evaluation 1:\n",
            "{\n",
            "  \"reasoning\": \"To assess whether the submission meets all the criteria listed, let's evaluate each criterion step-by-step:\\n\\n1. **Conciseness**: \\n   - The response isn't particularly concise. It includes a detailed suggestion to explore unexpressed thoughts and feelings, which, while potentially useful, might be more elaborate than necessary given the input. The response could have been shortened by omitting some exploratory questions or directly suggesting a simple solution.\\n\\n2. **Relevance**: \\n   - The response attempts to address the broader issue of managing negativity within a team. However, the original input does not explicitly ask for assistance or advice, but rather describes a situation. While relevance could be interpreted broadly in terms of addressing the challenge posed, the response doesn't directly address any specific query, because none was stated in the input.\\n\\n3. **Helpfulness**: \\n   - The response offers a somewhat helpful approach by encouraging reflection on unexpressed thoughts and feelings, which can be a valuable exercise in understanding team dynamics. However, the usefulness might be limited as it does not provide actionable steps for dealing with the team member's negativity directly.\\n\\n4. **Completeness**:\\n   - The response is not entirely complete in its coverage as it does not offer direct advice or multiple strategies for addressing the negativity issue within the team. While it aims to create an understanding of the emotional undercurrents, it does not provide a comprehensive solution or guidance.\\n\\nUpon considering each criterion, the submission fails to fully meet the criteria due to issues primarily with conciseness, relevance, and completeness.\\n\\nN\",\n",
            "  \"value\": \"N\",\n",
            "  \"score\": 0\n",
            "}\n",
            "\n",
            "🔹 Evaluation 2:\n",
            "{\n",
            "  \"reasoning\": \"To assess whether the submission meets the criteria, let's evaluate each one step by step:\\n\\n1. **Conciseness**: The original input is a simple \\\"thanks!\\\" indicating appreciation or gratitude. The response is quite lengthy compared to the input. While it is positive and polite, it is not as concise as it could be given the simplicity and brevity of the input. A more concise response might directly acknowledge the thanks and offer assistance in a more succinct manner.\\n\\n2. **Relevance**: The response acknowledges \\\"Thank you\\\" and provides supportive encouragement. However, it seems to anticipate more context (like a preparation for difficult conversations) that wasn't present in the original input. Therefore, while it addresses gratitude, it doesn't directly relate to any clearly provided specific question or context in the initial \\\"thanks!\\\"\\n\\n3. **Helpfulness**: The response offers to assist with future needs and encourages positive changes and collaboration, which is generally helpful advice. However, based on the simplicity of the input itself, the helpfulness factor is somewhat diminished as there was no specific request or problem presented to be addressed.\\n\\n4. **Completeness**: Completeness usually requires covering all aspects of a query. Since the only input is \\\"thanks,\\\" it's challenging to measure completeness. The response includes elements beyond what was explicitly referenced, suggesting more interpretation than required of the original prompt.\\n\\nIn summary, while the response is polite and positive, it doesn't entirely satisfy each criterion when considering the very sparse input. It is not concise relative to the input, it lacks clear relevance to any specific question or context given, is overly detailed for the simplicity of the gratitude expressed, and doesn't necessarily provide useful or necessary information in response to just a \\\"thanks!\\\" Therefore, the submission does not meet all criteria.\\n\\nN\",\n",
            "  \"value\": \"N\",\n",
            "  \"score\": 0\n",
            "}\n",
            "\n",
            "🔹 Evaluation 3:\n",
            "{\n",
            "  \"reasoning\": \"To evaluate whether the submission meets all the criteria, each criterion needs to be assessed separately:\\n\\n1. **Conciseness**: The response should be brief yet informative. Although the submission is polite and uses complete sentences, considering the input \\\"good night,\\\" the response seems unnecessarily lengthy. The input doesn't seem to imply a context that would require such a detailed response. Therefore, the submission is not concise concerning the input.\\n\\n2. **Relevance**: The response should directly address the user's statement or implied question. The submission does not address \\\"good night\\\" at all; instead, it responds as if it's concluding a customer service interaction. There is no connection between the submission and the input provided, indicating a lack of relevance.\\n\\n3. **Helpfulness**: The response should provide meaningful and useful information. Given that the input is simply \\\"good night,\\\" the submission does not offer pertinent information related to the input. It offers generic statements that have no relevance or help connected to the original statement.\\n\\n4. **Completeness**: The response should cover all aspects of the query sufficiently. Since the input \\\"good night\\\" doesn't seem to ask any question or imply any further context, the idea of completeness is somewhat irrelevant. However, the submission's response does not address the input directly or appropriately. There aren't any aspects of the input actually covered by the response.\\n\\nGiven the evaluation of each criterion, the submission fails to meet the criteria due to its lack of relevance, conciseness, helpfulness, and completeness in relation to the provided input.\\n\\nN\",\n",
            "  \"value\": \"N\",\n",
            "  \"score\": 0\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ideas for future analysis\n",
        "1.   **RAGAS for Conversational AI:**\n",
        "\n",
        "  RAGAS helps you evaluate how relevant the responses are by comparing the context, user intent, and factual accuracy.\n",
        "\n",
        "  It measures the **semantic relevance of the response**, making sure the chatbot answers **in line with the user's needs and expectations**.\n",
        "\n",
        "  RAGAS evaluates how well the system maintains **conversation continuity**, ensuring that each response makes sense based on previous exchanges.\n",
        "\n",
        "  Retrieval relevance is also considered—whether the **assistant pulls the right information** from the right sources and presents it in an **effective, coherent way.**\n",
        "\n",
        "  **Evaluating User Satisfaction**: Some advanced evaluation systems, including RAGAS, may allow for incorporating user feedback to improve the chatbot’s performance. If users indicate that responses were not relevant or helpful, this feedback can be used to adjust the relevance assessment and further fine-tune the chatbot's behavior.\n",
        "\n",
        "\n",
        "2. **Proper usage of langchain**\n",
        "\n",
        "For now it seems useless or I cannot leverage the power of it\n",
        "\n",
        "3. ...\n",
        "\n",
        "4. ..."
      ],
      "metadata": {
        "id": "VDa6IkbiBov2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8D7Y6g1-95b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "WZfLsepu95P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0NjAycvEHAr",
        "outputId": "03880ad7-9285-4a07-826b-1cf5c96c9813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl # Corrected the import statement\n",
        "print(openpyxl.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTRAX6igFFtH",
        "outputId": "f4a827c3-7aa9-4366-9595-7f4274c0d369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3j2U110FKU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}